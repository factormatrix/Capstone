import numpy as np
import pandas as pd
import streamlit as st

from xgboost import XGBClassifier, XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, f1_score, roc_auc_score,
    mean_squared_error, r2_score
)
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor

import shap

try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False

try:
    from catboost import CatBoostClassifier, CatBoostRegressor
    CATBOOST_AVAILABLE = True
except ImportError:
    CATBOOST_AVAILABLE = False


# -----------------------
# ìœ í‹¸ í•¨ìˆ˜ë“¤
# -----------------------
def is_tree_model(model):
    """
    RandomForest / XGBoost / LightGBM / CatBoost ê°™ì€ íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ì¸ì§€ í™•ì¸
    """
    tree_types = (RandomForestClassifier, RandomForestRegressor)

    # XGBoost
    try:
        import xgboost as xgb
        tree_types = tree_types + (xgb.XGBClassifier, xgb.XGBRegressor)
    except Exception:
        pass

    # LightGBM
    try:
        import lightgbm as lgb
        tree_types = tree_types + (lgb.LGBMClassifier, lgb.LGBMRegressor)
    except Exception:
        pass

    # CatBoost
    try:
        from catboost import CatBoostClassifier, CatBoostRegressor
        tree_types = tree_types + (CatBoostClassifier, CatBoostRegressor)
    except Exception:
        pass

    return isinstance(model, tree_types)


def read_csv_auto(file_obj):
    """
    ì—…ë¡œë“œëœ CSV íŒŒì¼ì„ ì¸ì½”ë”©ì„ ë°”ê¿” ê°€ë©° ì½ëŠ” í•¨ìˆ˜.
    UTF-8ì´ ì•ˆ ë˜ë©´ cp949, ê·¸ë˜ë„ ì•ˆ ë˜ë©´ ISO-8859-1 ì‹œë„.
    """
    # 1) UTF-8 ë¨¼ì € ì‹œë„
    try:
        file_obj.seek(0)
        return pd.read_csv(file_obj, encoding="utf-8")
    except UnicodeDecodeError:
        pass

    # 2) cp949 (í•œê¸€ ìœˆë„ìš° ê¸°ë³¸)
    try:
        file_obj.seek(0)
        return pd.read_csv(file_obj, encoding="cp949")
    except UnicodeDecodeError:
        pass

    # 3) ë§ˆì§€ë§‰ìœ¼ë¡œ ISO-8859-1 ê°™ì€ ë²”ìš© ì¸ì½”ë”©
    file_obj.seek(0)
    return pd.read_csv(file_obj, encoding="iso-8859-1", errors="replace")


def detect_cost_columns(df):
    """
    Q-COST ê´€ë ¨ ì»¬ëŸ¼ ìë™ íƒì§€ (ì¶”ì²œìš©)
    - ì˜ˆë°©ë¹„ìš©(prevention)
    - í‰ê°€/ê²€ì‚¬ë¹„ìš©(appraisal)
    - ë‚´ë¶€ ì‹¤íŒ¨(internal failure)
    - ì™¸ë¶€ ì‹¤íŒ¨(external failure)
    """
    cols = df.columns

    def match_keywords(keywords):
        return [c for c in cols if any(k.lower() in str(c).lower() for k in keywords)]

    prevention_cols = match_keywords(["ì˜ˆë°©", "prevention", "prevention_cost", "prevention cost", "P-COST", "P_COST"])
    appraisal_cols = match_keywords(["í‰ê°€", "ê²€ì‚¬", "inspection", "appraisal", "A-COST", "A_COST"])
    internal_failure_cols = match_keywords(["ë‚´ë¶€", "internal_failure", "internal failure", "IF-COST", "IF_COST"])
    external_failure_cols = match_keywords(["ì™¸ë¶€", "external_failure", "external failure", "EF-COST", "EF_COST"])

    return {
        "prevention": prevention_cols,
        "appraisal": appraisal_cols,
        "internal_failure": internal_failure_cols,
        "external_failure": external_failure_cols,
    }


def detect_target_column(df):
    """
    ì„±ê³µ/ì‹¤íŒ¨, ì–‘í’ˆ/ë¶ˆëŸ‰ ë“± íƒ€ê¹ƒ ì»¬ëŸ¼ ìë™ íƒì§€
    - ê°’ì´ 2~3ê°œ ì •ë„ì¸ ì»¬ëŸ¼ + ì´ë¦„ íŒ¨í„´ ê¸°ë°˜
    """
    candidates = []
    for col in df.columns:
        unique_vals = df[col].dropna().unique()
        if 1 < len(unique_vals) <= 3:
            candidates.append(col)

    preferred_patterns = [
        "ì„±ê³µ", "ì‹¤íŒ¨", "í•©ê²©", "ë¶ˆí•©ê²©", "ë¶ˆëŸ‰", "ì–‘í’ˆ",
        "pass_fail", "passfail", "pass", "fail",
        "target", "label", "y"
    ]
    for col in candidates:
        name = str(col).lower()
        if any(p.lower() in name for p in preferred_patterns):
            return col

    return candidates[0] if candidates else None


def binarize_target(series):
    """
    ì„±ê³µ/ì‹¤íŒ¨ í…ìŠ¤íŠ¸ë¥¼ 0/1ë¡œ ë§µí•‘
    """
    s = series.copy()
    mapping = {
        "ì„±ê³µ": 1, "success": 1, "pass": 1, "í•©ê²©": 1,
        "ì‹¤íŒ¨": 0, "fail": 0, "ë¶ˆí•©ê²©": 0, "ë¶ˆëŸ‰": 0, "ì–‘í’ˆ": 1
    }

    def _map(v):
        if pd.isna(v):
            return np.nan
        v_str = str(v).strip().lower()
        if v_str in mapping:
            return mapping[v_str]
        try:
            return float(v)
        except Exception:
            return np.nan

    s = s.map(_map)

    unique_vals = [u for u in s.dropna().unique()]
    if set(unique_vals).issubset({0, 1}):
        return s

    if len(unique_vals) == 2:
        lo, hi = sorted(unique_vals)
        return s.map(lambda x: 0 if x == lo else (1 if x == hi else np.nan))

    return s


def train_models_classification(X, y):
    results = {}

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    # 1) ë¡œì§€ìŠ¤í‹± íšŒê·€
    logreg = LogisticRegression(max_iter=500)
    logreg.fit(X_train, y_train)
    y_pred = logreg.predict(X_test)
    y_prob = logreg.predict_proba(X_test)[:, 1]

    results["Logistic Regression"] = {
        "model": logreg,
        "accuracy": accuracy_score(y_test, y_pred),
        "f1": f1_score(y_test, y_pred),
        "auc": roc_auc_score(y_test, y_prob),
    }

    # 2) ëœë¤í¬ë ˆìŠ¤íŠ¸
    rf = RandomForestClassifier(
        n_estimators=200,
        max_depth=10,
        min_samples_leaf=3,
        random_state=42,
        n_jobs=-1
    )
    rf.fit(X_train, y_train)
    y_pred = rf.predict(X_test)
    y_prob = rf.predict_proba(X_test)[:, 1]

    results["RandomForest"] = {
        "model": rf,
        "accuracy": accuracy_score(y_test, y_pred),
        "f1": f1_score(y_test, y_pred),
        "auc": roc_auc_score(y_test, y_prob),
    }

    # 3) XGBoost (ìˆìœ¼ë©´)
    if XGBOOST_AVAILABLE:
        xgb_model = xgb.XGBClassifier(
            n_estimators=200,
            max_depth=3,
            learning_rate=0.1,
            min_child_weight=5,
            subsample=0.8,
            colsample_bytree=0.8,
            eval_metric="logloss",
            random_state=42,
            n_jobs=-1,
        )

        xgb_model.fit(X_train, y_train)
        y_pred = xgb_model.predict(X_test)
        y_prob = xgb_model.predict_proba(X_test)[:, 1]

        results["XGBoost"] = {
            "model": xgb_model,
            "accuracy": accuracy_score(y_test, y_pred),
            "f1": f1_score(y_test, y_pred),
            "auc": roc_auc_score(y_test, y_prob),
        }

        if LIGHTGBM_AVAILABLE:
            try:
                lgb_model = lgb.LGBMClassifier(
                    n_estimators=200,
                    num_leaves=20,
                    max_depth=3,
                    min_child_samples=20,
                    learning_rate=0.05,
                    subsample=0.8,
                    colsample_bytree=0.8,
                    random_state=42,
                    n_jobs=-1,
                )
                lgb_model.fit(X_train, y_train)
                y_pred = lgb_model.predict(X_test)
                y_prob = lgb_model.predict_proba(X_test)[:, 1]

                results["LightGBM"] = {
                    "model": lgb_model,
                    "accuracy": accuracy_score(y_test, y_pred),
                    "f1": f1_score(y_test, y_pred),
                    "auc": roc_auc_score(y_test, y_prob),
                }

            except Exception as e:
                msg = str(e)
                if "special JSON characters in feature name" in msg or "feature name" in msg:
                    st.info(
                        "LightGBMì—ì„œ í”¼ì²˜ ì´ë¦„(ë¬¸ìì—´) ê´€ë ¨ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ "
                        "LightGBM ëª¨ë¸ì€ ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ ëª¨ë¸ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤."
                    )
                else:
                    raise

    if CATBOOST_AVAILABLE:
        cb_model = CatBoostClassifier(
            depth=5,
            learning_rate=0.05,
            iterations=500,
            l2_leaf_reg=3,
            random_state=42,
            verbose=False,
        )
        cb_model.fit(X_train, y_train)
        y_pred = cb_model.predict(X_test)
        y_prob = cb_model.predict_proba(X_test)[:, 1]

        results["CatBoost"] = {
            "model": cb_model,
            "accuracy": accuracy_score(y_test, y_pred),
            "f1": f1_score(y_test, y_pred),
            "auc": roc_auc_score(y_test, y_prob),
        }

    return results, (X_train, X_test, y_train, y_test)


def train_models_regression(X, y):
    """
    íšŒê·€ ëª¨ë¸ í•™ìŠµ (squared=False ì•ˆ ì“°ê³ , RMSE ì§ì ‘ ê³„ì‚°)
    """
    results = {}

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # 1) ì„ í˜• íšŒê·€
    lr = LinearRegression()
    lr.fit(X_train, y_train)
    y_pred = lr.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)

    results["Linear Regression"] = {
        "model": lr,
        "rmse": rmse,
        "r2": r2_score(y_test, y_pred),
    }

    # 2) ëœë¤í¬ë ˆìŠ¤íŠ¸
    rf = RandomForestRegressor(
        n_estimators=200,
        max_depth=10,
        min_samples_leaf=3,
        random_state=42,
        n_jobs=-1
    )
    rf.fit(X_train, y_train)
    y_pred = rf.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)

    results["RandomForest"] = {
        "model": rf,
        "rmse": rmse,
        "r2": r2_score(y_test, y_pred),
    }

    # 3) XGBoost (ìˆìœ¼ë©´)
    if XGBOOST_AVAILABLE:
        xgb_model = xgb.XGBRegressor(
            n_estimators=200,
            max_depth=3,
            learning_rate=0.1,
            min_child_weight=5,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            n_jobs=-1,
        )
        xgb_model.fit(X_train, y_train)
        y_pred = xgb_model.predict(X_test)

        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)

        results["XGBoost"] = {
            "model": xgb_model,
            "rmse": rmse,
            "r2": r2_score(y_test, y_pred),
        }

    if LIGHTGBM_AVAILABLE:
        try:
            lgb_model = lgb.LGBMRegressor(
                n_estimators=200,
                num_leaves=20,
                max_depth=3,
                min_child_samples=20,
                learning_rate=0.05,
                subsample=0.8,
                colsample_bytree=0.8,
                random_state=42,
                n_jobs=-1,
            )
            lgb_model.fit(X_train, y_train)
            y_pred = lgb_model.predict(X_test)

            mse = mean_squared_error(y_test, y_pred)
            rmse = np.sqrt(mse)

            results["LightGBM"] = {
                "model": lgb_model,
                "rmse": rmse,
                "r2": r2_score(y_test, y_pred),
            }

        except Exception as e:
            msg = str(e)
            if "special JSON characters in feature name" in msg or "feature name" in msg:
                st.info(
                    "LightGBMì—ì„œ í”¼ì²˜ ì´ë¦„(ë¬¸ìì—´) ê´€ë ¨ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ "
                    "LightGBM íšŒê·€ ëª¨ë¸ì€ ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ ëª¨ë¸ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤."
                )
            else:
                raise

    if CATBOOST_AVAILABLE:
        cb_model = CatBoostRegressor(
            depth=5,
            learning_rate=0.05,
            iterations=500,
            l2_leaf_reg=3,
            random_state=42,
            verbose=False,
        )
        cb_model.fit(X_train, y_train)
        y_pred = cb_model.predict(X_test)

        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)

        results["CatBoost"] = {
            "model": cb_model,
            "rmse": rmse,
            "r2": r2_score(y_test, y_pred),
        }

    return results, (X_train, X_test, y_train, y_test)


def remove_failure_related_features(X, failure_cols):
    """
    ì‹¤íŒ¨ë¹„ìš© ê´€ë ¨ ì»¬ëŸ¼(ë‚´ë¶€/ì™¸ë¶€/í†µí•©)ì„ X(ì…ë ¥ íŠ¹ì§•)ì—ì„œ ì œê±°í•˜ì—¬
    ëª¨ë¸ ëˆ„ì¶œ(leakage)ì„ ë°©ì§€í•œë‹¤.
    """
    failure_cols = [c for c in failure_cols if c in X.columns]
    return X.drop(columns=failure_cols, errors="ignore")


def show_min_q_cost_ratio(df, cost_cols, total_q_cost_col=None):
    """
    ë°ì´í„° ë‚´ì—ì„œ 'ì „ì²´ Q-COST'ê°€ ê°€ì¥ ë‚®ì•˜ë˜ ê´€ì¸¡ì¹˜ ê¸°ì¤€ìœ¼ë¡œ
    ì˜ˆë°©/í‰ê°€/ì‹¤íŒ¨ë¹„ìš© ë¹„ìœ¨ì„ ê³„ì‚°í•˜ì—¬ í•œ ë¬¸ì¥ìœ¼ë¡œ ì¶œë ¥í•œë‹¤.
    """
    numeric_df = df.select_dtypes(include=[np.number]).copy()
    if numeric_df.shape[0] == 0:
        return

    prevention_cols = [c for c in cost_cols.get("prevention", []) if c in numeric_df.columns]
    appraisal_cols = [c for c in cost_cols.get("appraisal", []) if c in numeric_df.columns]
    internal_failure_cols = [c for c in cost_cols.get("internal_failure", []) if c in numeric_df.columns]
    external_failure_cols = [c for c in cost_cols.get("external_failure", []) if c in numeric_df.columns]

    failure_cols = [c for c in (internal_failure_cols + external_failure_cols) if c in numeric_df.columns]

    if not (prevention_cols or appraisal_cols or failure_cols):
        return

    p = numeric_df[prevention_cols].sum(axis=1) if prevention_cols else pd.Series(0.0, index=numeric_df.index)
    a = numeric_df[appraisal_cols].sum(axis=1) if appraisal_cols else pd.Series(0.0, index=numeric_df.index)
    f = numeric_df[failure_cols].sum(axis=1) if failure_cols else pd.Series(0.0, index=numeric_df.index)

    if total_q_cost_col is not None and total_q_cost_col in numeric_df.columns:
        total_q = numeric_df[total_q_cost_col]
    else:
        total_q = p + a + f

    mask = total_q > 0
    if mask.sum() == 0:
        return

    total_q = total_q[mask]
    p = p[mask]
    a = a[mask]
    f = f[mask]

    idx_min = total_q.idxmin()
    total_min = float(total_q.loc[idx_min])
    if total_min <= 0:
        return

    p_ratio = float(p.loc[idx_min]) / total_min * 100
    a_ratio = float(a.loc[idx_min]) / total_min * 100
    f_ratio = float(f.loc[idx_min]) / total_min * 100

    st.markdown(
        f"ğŸ’¡ê³¼ê±° ë°ì´í„°ì—ì„œ ì „ì²´ í’ˆì§ˆë¹„ìš©ì´ ê°€ì¥ ë‚®ì•˜ë˜ ê´€ì¸¡ ì‹œì ì˜ ë¹„ìš© êµ¬ì¡°ëŠ” "
        f"ì˜ˆë°© ë¹„ìš© **{p_ratio:.1f}%**, í‰ê°€ë¹„ìš© **{a_ratio:.1f}%**, "
        f"ì‹¤íŒ¨ë¹„ìš© **{f_ratio:.1f}%** ì…ë‹ˆë‹¤."
    )



def build_scenario_result(df, cost_cols, failure_col_name=None, exclude_cols=None):
    """
    ì˜ˆë°©/í‰ê°€ ë¹„ìš©ì„ ë³€ê²½í–ˆì„ ë•Œ ì‹¤íŒ¨ë¹„ìš© ë³€í™” ì‹œë®¬ë ˆì´ì…˜
    - ì‹¤íŒ¨ë¹„ìš©: ì‚¬ìš©ìê°€ ì§€ì •í•œ í†µí•© ì‹¤íŒ¨ë¹„ìš© ì»¬ëŸ¼ ë˜ëŠ” ë‚´ë¶€/ì™¸ë¶€ ì‹¤íŒ¨ë¹„ìš© í•©ê³„
    - íƒ€ê¹ƒ: ì‹¤íŒ¨ë¹„ìš© (íšŒê·€) ë˜ëŠ” ì´ì§„ íƒ€ê¹ƒ (ë¶„ë¥˜)
    """
    prevention_cols = cost_cols.get("prevention", [])
    appraisal_cols = cost_cols.get("appraisal", [])
    internal_failure_cols = cost_cols.get("internal_failure", [])
    external_failure_cols = cost_cols.get("external_failure", [])

    df_num = df.select_dtypes(include=[np.number]).copy()

    failure_cols = []
    if failure_col_name is not None and failure_col_name in df_num.columns:
        failure_cols = [failure_col_name]
    else:
        failure_cols = [c for c in (internal_failure_cols + external_failure_cols) if c in df_num.columns]

    if not failure_cols:
        return None, "ì‹¤íŒ¨ë¹„ìš©(íƒ€ê¹ƒ) ìˆ˜ì¹˜ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹¤íŒ¨ë¹„ìš© ì»¬ëŸ¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”."

    df_num["failure_cost"] = df_num[failure_cols].sum(axis=1)

    feature_cols = list(set([c for c in prevention_cols + appraisal_cols if c in df_num.columns]))
    if not feature_cols:
        feature_cols = [c for c in df_num.columns if c != "failure_cost"]

    data = df_num[feature_cols + ["failure_cost"]].dropna()
    if data.shape[0] < 20:
        return None, "ì‹œë®¬ë ˆì´ì…˜ì„ í•˜ê¸°ì—ëŠ” ìœ íš¨í•œ ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤."

    X = data[feature_cols]
    y = data["failure_cost"]

    if exclude_cols:
        drop_cols = [c for c in exclude_cols if c in X.columns]
        X = X.drop(columns=drop_cols, errors="ignore")

    failure_related_cols = internal_failure_cols + external_failure_cols
    if failure_col_name is not None:
        failure_related_cols.append(failure_col_name)
    X = remove_failure_related_features(X, failure_related_cols)

    unique_vals = sorted(pd.Series(y).dropna().unique())
    is_binary = unique_vals in ([0, 1], [0], [1])

    if is_binary:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )

        model = XGBClassifier(
            n_estimators=300,
            max_depth=5,
            learning_rate=0.05,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            eval_metric="logloss"
        )

        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        metric_value = accuracy_score(y_test, y_pred)
        metric_name = "Accuracy"

        results = {"XGBClassifier": {"model": model, "accuracy": metric_value}}
        best_model_name = "XGBClassifier"

    else:
        results, (X_train, X_test, y_train, y_test) = train_models_regression(X, y)

        if "XGBoost" in results:
            best_model_name = "XGBoost"
        else:
            best_model_name = max(results.keys(), key=lambda m: results[m]["r2"])

        model = results[best_model_name]["model"]
        y_pred = model.predict(X_test)
        metric_value = r2_score(y_test, y_pred)
        metric_name = "R2"

    base_point = X.mean(axis=0).to_frame().T

    baseline_prevention = float(base_point[prevention_cols].sum(axis=1).iloc[0]) if prevention_cols else 0.0
    baseline_appraisal = float(base_point[appraisal_cols].sum(axis=1).iloc[0]) if appraisal_cols else 0.0

    def predict_with_factor(prevention_factor, appraisal_factor):
        x_new = base_point.copy()
        for c in prevention_cols:
            if c in x_new.columns:
                x_new[c] = x_new[c] * (1 + prevention_factor)
        for c in appraisal_cols:
            if c in x_new.columns:
                x_new[c] = x_new[c] * (1 + appraisal_factor)

        if is_binary:
            proba = model.predict_proba(x_new)[0][1]
            return float(proba)
        else:
            return float(model.predict(x_new)[0])

    baseline_cost = predict_with_factor(0.0, 0.0)

    return {
        "model": model,
        "best_model_name": best_model_name,
        "feature_cols": feature_cols,
        "prevention_cols": prevention_cols,
        "appraisal_cols": appraisal_cols,
        "baseline_cost": baseline_cost,
        "baseline_prevention": baseline_prevention,
        "baseline_appraisal": baseline_appraisal,
        "predict_func": predict_with_factor,
        "metrics": results,
        "task_type": "classification" if is_binary else "regression",
        "metric_name": metric_name,
        "metric_value": metric_value,
    }, None


# -----------------------
# Google Generative AI ì±—ë´‡
# -----------------------
def generate_ai_response(user_message, api_key, analysis_summary=""):
    import google.generativeai as genai

    genai.configure(api_key=api_key)
    model = genai.GenerativeModel("gemini-2.5-flash")

    system_prompt = f"""
    ë‹¹ì‹ ì€ ì¤‘ì†Œê¸°ì—…ì˜ Q-COST(ì˜ˆë°©ë¹„ìš©, í‰ê°€ë¹„ìš©, ë‚´ë¶€/ì™¸ë¶€ ì‹¤íŒ¨ë¹„ìš©) ë¶„ì„ì„ ë„ì™€ì£¼ëŠ” AI ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
    íšŒê·€ë¶„ì„, ëœë¤í¬ë ˆìŠ¤íŠ¸, XGBoost, SHAP ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í’ˆì§ˆ ë¹„ìš© êµ¬ì¡°ì™€ ì˜ì‚¬ê²°ì •ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

    ì•„ë˜ëŠ” í˜„ì¬ ë°ì´í„° ë¶„ì„ ìš”ì•½ì…ë‹ˆë‹¤:

    {analysis_summary}

    ì´ ìš”ì•½ì„ ì°¸ê³ í•´ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´:
    - í•œêµ­ì–´ë¡œ,
    - ìµœëŒ€í•œ ì‰½ê²Œ,
    - ìˆ«ìì™€ ì§ê´€ì  í‘œí˜„ì„ í•¨ê»˜ ì‚¬ìš©í•´ì„œ
    ì„¤ëª…í•´ ì£¼ì„¸ìš”.
    """

    full_prompt = system_prompt + "\n\nì‚¬ìš©ì ì§ˆë¬¸:\n" + user_message
    response = model.generate_content(full_prompt)
    return response.text


def get_shap_importance_df(model, X_train, feature_names):
    """
    SHAP ê°’ì„ ì´ìš©í•´ ê° ë³€ìˆ˜ì˜ í‰ê·  |SHAP| (ì ˆëŒ€ê°’) ì¤‘ìš”ë„ë¥¼ ìˆ«ì í…Œì´ë¸”ë¡œ ë°˜í™˜.
    (UI ìˆ˜ì • ê¸ˆì§€ íŒŒíŠ¸: í‘œ ë Œë”ë§ê³¼ ì—°ê²°ë¨)
    """
    sample = X_train
    if X_train.shape[0] > 500:
        sample = X_train.sample(500, random_state=42)

    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(sample)

    sv = shap_values
    if isinstance(sv, list):
        sv = sv[1] if len(sv) > 1 else sv[0]

    sv = np.array(sv)
    if sv.ndim > 2:
        n_features = sv.shape[-1]
        sv = sv.reshape(-1, n_features)

    mean_shap = np.mean(sv, axis=0)
    mean_abs_shap = np.mean(np.abs(sv), axis=0)

    mean_shap = np.array(mean_shap).ravel()
    mean_abs_shap = np.array(mean_abs_shap).ravel()

    feature_names = list(feature_names)
    if len(feature_names) != len(mean_abs_shap):
        n = min(len(feature_names), len(mean_abs_shap), len(mean_shap))
        feature_names = feature_names[:n]
        mean_abs_shap = mean_abs_shap[:n]
        mean_shap = mean_shap[:n]

    shap_df = pd.DataFrame({
        "feature": feature_names,
        "mean_shap": mean_shap,
        "mean_abs_shap": mean_abs_shap
    }).sort_values("mean_abs_shap", ascending=False).reset_index(drop=True)

    return shap_df


def render_shap_table(shap_df):
    """
    Streamlit column_configë¥¼ í™œìš©í•œ SHAP í‘œ ë Œë”ë§ (UI ìˆ˜ì • ê¸ˆì§€ íŒŒíŠ¸)
    """
    df = shap_df.copy()

    total = df["mean_abs_shap"].sum()
    df["importance_pct"] = df["mean_abs_shap"] / total * 100 if total > 0 else 0.0

    def arrow(v):
        if v > 0:
            return "â†‘ ì¦ê°€ ë°©í–¥"
        elif v < 0:
            return "â†“ ê°ì†Œ ë°©í–¥"
        return "â†’ ì˜í–¥ ê±°ì˜ ì—†ìŒ"

    df["direction_arrow"] = df["mean_shap"].apply(arrow)

    show_cols = ["feature", "importance_pct", "direction_arrow", "mean_shap"]

    st.data_editor(
        df[show_cols],
        column_config={
            "feature": st.column_config.TextColumn("ë³€ìˆ˜ëª…"),
            "importance_pct": st.column_config.ProgressColumn(
                "ì¤‘ìš”ë„ (|SHAP| ê¸°ì¤€ ë¹„ìœ¨)",
                help="ê° ë³€ìˆ˜ì˜ |SHAP| í•© ëŒ€ë¹„ ë¹„ì¤‘(%)",
                format="%.1f",
                min_value=0.0,
                max_value=100.0,
            ),
            "direction_arrow": st.column_config.TextColumn(
                "ì˜í–¥ ë°©í–¥",
                help="â†‘: íƒ€ê¹ƒ(ì‹¤íŒ¨/ë¹„ìš©) ì¦ê°€, â†“: íƒ€ê¹ƒ ê°ì†Œ, â†’: ê±°ì˜ ì˜í–¥ ì—†ìŒ",
            ),
            "mean_shap": st.column_config.NumberColumn(
                "í‰ê·  SHAP ê°’",
                help="ì–‘ìˆ˜: íƒ€ê¹ƒ ì¦ê°€ ë°©í–¥, ìŒìˆ˜: íƒ€ê¹ƒ ê°ì†Œ ë°©í–¥",
                format="%.4f",
            ),
        },
        hide_index=True,
        use_container_width=True,
    )


def compute_feature_r2(X, y):
    """
    ê° ì…ë ¥ ë³€ìˆ˜ë³„ë¡œ ë‹¨ìˆœ ëª¨ë¸ì„ ëŒë ¤ RÂ² ì ìˆ˜ë¥¼ ê³„ì‚°.
    (UI ìˆ˜ì • ê¸ˆì§€ íŒŒíŠ¸: í‘œ ë Œë”ë§ê³¼ ì—°ê²°ë¨)
    """
    rows = []
    for col in X.columns:
        if X[col].nunique() < 2:
            continue

        x_col = X[[col]]
        model = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            min_samples_leaf=3,
            n_jobs=-1
        )
        model.fit(x_col, y)
        y_pred = model.predict(x_col)
        r2 = r2_score(y, y_pred)

        rows.append({"feature": col, "RÂ²_single": r2})

    if not rows:
        return pd.DataFrame(columns=["feature", "RÂ²_single"])

    return pd.DataFrame(rows).sort_values("RÂ²_single", ascending=False).reset_index(drop=True)


def render_feature_r2_table(feature_r2_df):
    """
    ë‹¨ì¼ ë³€ìˆ˜ë³„ RÂ² ì ìˆ˜ í‘œ ë Œë”ë§ (UI ìˆ˜ì • ê¸ˆì§€ íŒŒíŠ¸)
    """
    if feature_r2_df.shape[0] == 0:
        st.info("ê° ë³€ìˆ˜ë³„ RÂ²ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ìœ íš¨í•œ ìˆ«ìí˜• íŠ¹ì§•ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        return

    df = feature_r2_df.copy()
    df["R2_for_bar"] = df["RÂ²_single"].clip(lower=0.0)

    show_cols = ["feature", "R2_for_bar", "RÂ²_single"]

    st.data_editor(
        df[show_cols],
        column_config={
            "feature": st.column_config.TextColumn("ë³€ìˆ˜ëª…"),
            "R2_for_bar": st.column_config.ProgressColumn(
                "RÂ² (0~1 ê¸°ì¤€)",
                help="ê° ë³€ìˆ˜ í•˜ë‚˜ë§Œ ì‚¬ìš©í•œ ëª¨ë¸ì˜ RÂ²ë¥¼ ê·¸ëŒ€ë¡œ 0~1 êµ¬ê°„ì—ì„œ ë§‰ëŒ€ë¡œ í‘œí˜„í•©ë‹ˆë‹¤.\n"
                     "ìŒìˆ˜ RÂ²ëŠ” ë§‰ëŒ€ê°€ 0ìœ¼ë¡œ í‘œì‹œë˜ê³ , ì‹¤ì œ ê°’ì€ ì˜¤ë¥¸ìª½ ìˆ«ìì—ì„œ í™•ì¸í•˜ì„¸ìš”.",
                format="%.2f",
                min_value=0.0,
                max_value=1.0,
            ),
            "RÂ²_single": st.column_config.NumberColumn(
                "ë‹¨ì¼ ë³€ìˆ˜ RÂ² (ì‹¤ì œ ê°’)",
                help="ê° ë³€ìˆ˜ í•˜ë‚˜ë§Œ ì‚¬ìš©í•œ ëª¨ë¸ì˜ ì‹¤ì œ RÂ² ê°’ì…ë‹ˆë‹¤. (ìŒìˆ˜ ê°€ëŠ¥)",
                format="%.4f",
            ),
        },
        hide_index=True,
        use_container_width=True,
    )


# -----------------------
# Streamlit ì•± ì‹œì‘
# -----------------------
st.set_page_config(page_title="Q-COST AI", layout="wide")
st.markdown("<h1 style='text-align: center;'>Q-COST AI</h1>", unsafe_allow_html=True)

tab_analysis, tab_chat = st.tabs(["ìë™ Q-COST ë¶„ì„", "Q-COST AI ëŒ€í™”"])

if "analysis_summary" not in st.session_state:
    st.session_state["analysis_summary"] = ""

# -----------------------
# ì‚¬ì´ë“œë°” UI (ì—…ë¡œë“œ + ì„¤ì •)
# -----------------------
with st.sidebar:
    st.header("ğŸ”‘ ì„¤ì •")
    google_api_key = st.sidebar.text_input("Google API Key", type="password")

    if google_api_key and google_api_key.strip():
        st.sidebar.success("API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.", icon="âœ…")
    else:
        st.sidebar.info("Google API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")


    st.markdown("---")

    st.header("ğŸ“¤ ë°ì´í„° ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader(
        "CSV ë˜ëŠ” Excel íŒŒì¼",
        type=["csv", "xlsx", "xls"]
    )

    st.caption("ì—…ë¡œë“œ í›„, ë¶„ì„ íƒ­ì—ì„œ **ë¹„ìš© ì»¬ëŸ¼ â†’ íƒ€ê¹ƒ â†’ ì œì™¸ ì»¬ëŸ¼** ìˆœì„œë¡œ ì„¤ì •í•˜ì„¸ìš”.")


# =======================
# 1) ë¶„ì„ íƒ­
# =======================
with tab_analysis:
    st.subheader("âœ” ë°ì´í„° í™•ì¸")

    if uploaded_file is None:
        st.info("ì‚¬ì´ë“œë°”ì—ì„œ CSV ë˜ëŠ” Excel íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        st.stop()

    # íŒŒì¼ ì½ê¸°
    if uploaded_file.name.endswith(".csv"):
        df = read_csv_auto(uploaded_file)
    else:
        df = pd.read_excel(uploaded_file)

    st.write("#### ì›ë³¸ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
    st.dataframe(df.head(), use_container_width=True)

    numeric_cols = list(df.select_dtypes(include=[np.number]).columns)
    if len(numeric_cols) == 0:
        st.warning("ìˆ«ìí˜• ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. (íšŒê·€/ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ì„ ìœ„í•´ ìˆ«ìí˜• ë¹„ìš© ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.)")
        st.stop()

    st.markdown("<div style='margin-top:40px'></div>", unsafe_allow_html=True)
    # -------------------------
    # Q-COST ì»¬ëŸ¼ ìë™ íƒì§€ + ì§ì ‘ ì§€ì •
    # -------------------------
    st.subheader("âœ” Q-COST ì»¬ëŸ¼ ì§€ì • (ì˜ˆë°© Â· í‰ê°€ Â· ì‹¤íŒ¨)")
    auto_cost_cols = detect_cost_columns(df)
    st.caption("ìë™ìœ¼ë¡œ ì°¾ì•„ë³¸ ê²°ê³¼ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ë„£ì–´ë‘ì—ˆì–´ìš”. í•„ìš”í•˜ë©´ ì•„ë˜ì—ì„œ ì§ì ‘ ë°”ê¿”ì£¼ì„¸ìš”.")

    all_columns = list(df.columns)
    numeric_cols = df.select_dtypes(include=[np.number]).columns

    c1, c2, c3 = st.columns(3)

    with c1:
        prevention_selected = st.multiselect(
            "ì˜ˆë°©ë¹„ìš©(P)",
            options=all_columns,
            default=auto_cost_cols["prevention"],
            help="ì˜ˆë°© í™œë™, êµìœ¡, ì„¤ë¹„ ê°œì„  ë“±ì— ì“°ì´ëŠ” ë¹„ìš© ì»¬ëŸ¼"
        )

    with c2:
        appraisal_selected = st.multiselect(
            "í‰ê°€ë¹„ìš©(A)",
            options=all_columns,
            default=auto_cost_cols["appraisal"],
            help="ê²€ì‚¬, ì‹œí—˜, í’ˆì§ˆì ê²€ì— ë“¤ì–´ê°€ëŠ” ë¹„ìš© ì»¬ëŸ¼"
        )

    with c3:
        # ì‹¤íŒ¨ë¹„ìš© ê¸°ë³¸ê°’(ì›ë³¸ ë¡œì§ ìœ ì§€): ë‚´ë¶€+ì™¸ë¶€ ì‹¤íŒ¨ ìë™ ì¶”ì²œ
        failure_default = auto_cost_cols["internal_failure"] + auto_cost_cols["external_failure"]

        # ìë™ íƒì§€ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì´ë¦„ ê¸°ë°˜ ì¶”ì²œ(ì›ë³¸ ë¡œì§ ìœ ì§€)
        if not failure_default:
            for c in numeric_cols:
                name = str(c).lower()
                if any(k in name for k in ["ì‹¤íŒ¨", "ë¶ˆëŸ‰", "failure", "defect"]):
                    failure_default.append(c)

        failure_selected_cols = st.multiselect(
            "ì‹¤íŒ¨ë¹„ìš©(F)",
            options=list(numeric_cols),
            default=failure_default,
            help="ì‹¤íŒ¨ë¹„ìš© ì»¬ëŸ¼(ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥)"
        )

    st.caption(
        f"ì„ íƒ í˜„í™© Â· ì˜ˆë°© {len(prevention_selected)}ê°œ / í‰ê°€ {len(appraisal_selected)}ê°œ / ì‹¤íŒ¨ {len(failure_selected_cols)}ê°œ"
    )

    cost_cols = {
        "prevention": prevention_selected,
        "appraisal": appraisal_selected,
        "internal_failure": failure_selected_cols,
        "external_failure": [],
    }

    st.markdown("<div style='margin-top:40px'></div>", unsafe_allow_html=True)
    # -------------------------
    # íƒ€ê¹ƒ ì„ íƒ (ê¸°ì¡´ ì»¬ëŸ¼ vs ìë™ í•©ì‚°)
    # -------------------------
    st.subheader("âœ” íƒ€ê¹ƒ(Total Q-COST) ì„¤ì •")
    target_option = st.radio("ì¢…ì†ë³€ìˆ˜(ì´ í’ˆì§ˆë¹„ìš©) ì„¤ì •",
                         ["ê¸°ì¡´ ì»¬ëŸ¼ ì„ íƒ", "ìë™ ê³„ì‚° (ì˜ˆë°©+í‰ê°€+ì‹¤íŒ¨)"], horizontal=True)


    numeric_df = df.select_dtypes(include=[np.number]).copy()

    # í•©ì‚°ì— ì‚¬ìš©í•  ì»¬ëŸ¼ë“¤(ìˆ«ìí˜•ë§Œ)
    p_cols = [c for c in prevention_selected if c in numeric_df.columns]
    a_cols = [c for c in appraisal_selected if c in numeric_df.columns]
    f_cols = [c for c in failure_selected_cols if c in numeric_df.columns]

    target_col = None
    total_q_cost_col = None

    if target_option == "ê¸°ì¡´ ì»¬ëŸ¼ ì„ íƒ":
        target_col = st.selectbox(
            "ì´ í’ˆì§ˆë¹„ìš©(Total Q-COST) ì»¬ëŸ¼ ì„ íƒ",
            ["(ì„ íƒ)"] + list(numeric_df.columns),
        )
        if target_col == "(ì„ íƒ)":
            target_col = None
    else:
        if p_cols or a_cols or f_cols:
            temp_total_col = "TOTAL_Q_COST"
            suffix = 1
            while temp_total_col in df.columns:
                temp_total_col = f"TOTAL_Q_COST_{suffix}"
                suffix += 1

            numeric_df[temp_total_col] = numeric_df[p_cols + a_cols + f_cols].sum(axis=1)
            df[temp_total_col] = numeric_df[temp_total_col]
            target_col = temp_total_col
            total_q_cost_col = temp_total_col
            st.success(f"'{temp_total_col}' ì»¬ëŸ¼ì´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            st.warning("ìë™ í•©ì‚°ì„ ìœ„í•´ ì˜ˆë°©/í‰ê°€/ì‹¤íŒ¨ë¹„ìš© ì»¬ëŸ¼ ì¤‘ ìµœì†Œ 1ê°œ ì´ìƒì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
    
    st.markdown("<div style='margin-top:40px'></div>", unsafe_allow_html=True)
    # -------------------------
    # ë©”ì¸ ëª¨ë¸(ë¶„ì„) ì‹¤í–‰
    # -------------------------
    st.subheader("âœ” ë©”ì¸ ëª¨ë¸ ë¶„ì„")

    if target_col is None or target_col not in df.columns:
        st.info("íƒ€ê¹ƒ ì»¬ëŸ¼ì„ ì„ íƒí•˜ë©´ ë©”ì¸ ëª¨ë¸ í•™ìŠµì´ ì§„í–‰ë©ë‹ˆë‹¤.")
    else:
        main_candidate_cols = [c for c in numeric_df.columns if c != target_col]
        main_exclude_cols = st.multiselect(
            "ë©”ì¸ ëª¨ë¸ì—ì„œ ë…ë¦½ë³€ìˆ˜ì—ì„œ ì œì™¸í•  ì»¬ëŸ¼ ì„ íƒ",
            options=main_candidate_cols,
            help="ì‹¤íŒ¨ìœ¨/ë¶ˆëŸ‰ë¥  ë“± íƒ€ê¹ƒì„ ì‚¬ì‹¤ìƒ ê·¸ëŒ€ë¡œ ë°˜ì˜í•˜ëŠ” ì§€í‘œëŠ” ì œì™¸í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤."
        )

        # íƒ€ê¹ƒ ì²˜ë¦¬ (ì´ì§„/ì—°ì† ìë™)
        target_series = binarize_target(df[target_col])
        unique_vals = target_series.dropna().unique()
        is_binary = len(unique_vals) <= 2 and set(unique_vals).issubset({0, 1})

        numeric_df[target_col] = target_series
        data = numeric_df.dropna(subset=[target_col])

        if data.shape[0] < 5:
            st.warning("ìœ íš¨í•œ ë°ì´í„° í–‰ì´ 5ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤. ë” ë§ì€ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¢‹ìŠµë‹ˆë‹¤.")
        else:
            X = data.drop(columns=[target_col])
            y = data[target_col]

            if main_exclude_cols:
                X = X.drop(columns=[c for c in main_exclude_cols if c in X.columns], errors="ignore")

            # (ê¸°ì¡´ ë¡œì§ ìœ ì§€) í•„ìš”ì‹œ ì‹¤íŒ¨ë¹„ìš© ê´€ë ¨ ì»¬ëŸ¼ ì œê±°í•˜ì—¬ leakage ë°©ì§€
            failure_related_cols = list(failure_selected_cols)
            remove_failure_features = True
            if total_q_cost_col is not None and target_col == total_q_cost_col:
                remove_failure_features = False
            if remove_failure_features and failure_related_cols:
                X = remove_failure_related_features(X, failure_related_cols)

            st.write("### ëª¨ë¸ í•™ìŠµ ê²°ê³¼")

            if is_binary:
                st.write("#### (ë¶„ë¥˜) ì„±ê³µ/ì‹¤íŒ¨ ë˜ëŠ” ì–‘í’ˆ/ë¶ˆëŸ‰ ì˜ˆì¸¡")

                clf_results, (X_train, X_test, y_train, y_test) = train_models_classification(X, y)

                best_overall_name = max(clf_results.keys(), key=lambda m: clf_results[m]["auc"])
                best_overall_model = clf_results[best_overall_name]["model"]

                tree_candidates = [name for name, res in clf_results.items() if is_tree_model(res["model"])]

                shap_model_name = None
                if is_tree_model(best_overall_model):
                    shap_model_name = best_overall_name
                elif tree_candidates:
                    shap_model_name = max(tree_candidates, key=lambda m: clf_results[m]["auc"])

                if shap_model_name is not None:
                    shap_model = clf_results[shap_model_name]["model"]
                    if shap_model_name == best_overall_name:
                        title = f"#### SHAP ë³€ìˆ˜ ì¤‘ìš”ë„ (ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {shap_model_name})"
                    else:
                        title = (
                            "#### SHAP ë³€ìˆ˜ ì¤‘ìš”ë„ "
                            f"(Tree ëª¨ë¸ ê¸°ì¤€: {shap_model_name}, "
                            f"ì „ì²´ ìµœê³  ëª¨ë¸(AUC): {best_overall_name})"
                        )
                    st.write(title)

                    shap_df_best = get_shap_importance_df(shap_model, X_train, X.columns)
                    render_shap_table(shap_df_best)
                else:
                    st.info("íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ì´ ì—†ì–´ SHAP ë³€ìˆ˜ ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëŒ€ì‹  ì„±ëŠ¥ ì§€í‘œë§Œ ì°¸ê³ í•´ì£¼ì„¸ìš”.")

                summary_lines = ["[ë¶„ë¥˜ ëª¨ë¸ ìš”ì•½]"]
                for name, r in clf_results.items():
                    summary_lines.append(
                        f"- {name}: Accuracy={r['accuracy']:.3f}, F1={r['f1']:.3f}, AUC={r['auc']:.3f}"
                    )
                summary_lines.append(f"- ì „ì²´ ìµœê³  ì„±ëŠ¥ ëª¨ë¸(AUC ê¸°ì¤€): {best_overall_name}")
                if shap_model_name is not None and shap_model_name != best_overall_name:
                    summary_lines.append(f"- SHAP ë³€ìˆ˜ ì¤‘ìš”ë„ëŠ” íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ '{shap_model_name}' ê¸°ì¤€ìœ¼ë¡œ ì‚°ì¶œ")
                summary_lines.append(f"- ì‚¬ìš©ëœ íŠ¹ì§• ìˆ˜: {X.shape[1]}")
                summary_lines.append(f"- íƒ€ê¹ƒ ì»¬ëŸ¼: {target_col}")
                st.session_state["analysis_summary"] = "\n".join(summary_lines)

            else:
                st.write("#### (íšŒê·€) Total Q-COST ì˜ˆì¸¡")

                reg_results, (X_train, X_test, y_train, y_test) = train_models_regression(X, y)

                # âœ… UI ìˆ˜ì • ê¸ˆì§€
                st.write("#### ë‹¨ì¼ ë³€ìˆ˜ë³„ RÂ² ì ìˆ˜")
                feature_r2_df = compute_feature_r2(X, y)
                render_feature_r2_table(feature_r2_df)

                best_overall_name = max(reg_results.keys(), key=lambda m: reg_results[m]["r2"])
                best_overall_model = reg_results[best_overall_name]["model"]

                tree_candidates = [name for name, res in reg_results.items() if is_tree_model(res["model"])]

                shap_model_name = None
                if is_tree_model(best_overall_model):
                    shap_model_name = best_overall_name
                elif tree_candidates:
                    shap_model_name = max(tree_candidates, key=lambda m: reg_results[m]["r2"])

                if shap_model_name is not None:
                    shap_model = reg_results[shap_model_name]["model"]
                    if shap_model_name == best_overall_name:
                        title = f"#### SHAP ë³€ìˆ˜ ì¤‘ìš”ë„ (ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {shap_model_name})"
                    else:
                        title = (
                            "#### SHAP ë³€ìˆ˜ ì¤‘ìš”ë„ "
                            f"(Tree ëª¨ë¸ ê¸°ì¤€: {shap_model_name}, "
                            f"ì „ì²´ ìµœê³  ëª¨ë¸(RÂ²): {best_overall_name})"
                        )
                    st.write(title)

                    shap_df_best = get_shap_importance_df(shap_model, X_train, X.columns)
                    render_shap_table(shap_df_best)
                else:
                    st.info("íŠ¸ë¦¬ ê¸°ë°˜ íšŒê·€ ëª¨ë¸ì´ ì—†ì–´ SHAP ë³€ìˆ˜ ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëŒ€ì‹  RÂ², RMSE ì§€í‘œë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”.")

                summary_lines = ["[íšŒê·€ ëª¨ë¸ ìš”ì•½]"]
                for name, r in reg_results.items():
                    summary_lines.append(f"- {name}: RMSE={r['rmse']:.3f}, RÂ²={r['r2']:.3f}")
                summary_lines.append(f"- ì „ì²´ ìµœê³  ì„±ëŠ¥ ëª¨ë¸(RÂ² ê¸°ì¤€): {best_overall_name}")
                if shap_model_name is not None and shap_model_name != best_overall_name:
                    summary_lines.append(f"- SHAP ë³€ìˆ˜ ì¤‘ìš”ë„ëŠ” íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ '{shap_model_name}' ê¸°ì¤€ìœ¼ë¡œ ì‚°ì¶œ")
                summary_lines.append(f"- ì‚¬ìš©ëœ íŠ¹ì§• ìˆ˜: {X.shape[1]}")
                summary_lines.append(f"- íƒ€ê¹ƒ ì»¬ëŸ¼: {target_col}")
                st.session_state["analysis_summary"] = "\n".join(summary_lines)

    # -------------------------
    # ì°¸ê³ : ê³¼ê±° ìµœì†Œ ë¹„ìš©êµ¬ì¡°
    # -------------------------
    show_min_q_cost_ratio(df, cost_cols, total_q_cost_col=total_q_cost_col)

    st.markdown("<div style='margin-top:40px'></div>", unsafe_allow_html=True)

    # -------------------------
    # ì‹œë‚˜ë¦¬ì˜¤ (ë¡œì§ ì ˆëŒ€ ë³€ê²½ ê¸ˆì§€: ì¶œë ¥ UIë§Œ ë³€ê²½)
    # -------------------------
    st.markdown("---")
    st.subheader("ğŸ” ì˜ˆë°©/í‰ê°€ë¹„ìš© ë³€í™” ì‹œë‚˜ë¦¬ì˜¤ (ì‹¤íŒ¨ë¹„ìš©/ì´ë¹„ìš© ë³€í™” í™•ì¸)")

    # ì‹œë‚˜ë¦¬ì˜¤ íšŒê·€ì—ì„œ ë…ë¦½ë³€ìˆ˜ì—ì„œ ì œì™¸í•  ì»¬ëŸ¼ ì„ íƒ
    scenario_candidate_cols = list(df.select_dtypes(include=[np.number]).columns)

    scenario_exclude_cols = st.multiselect(
        "ì‹œë‚˜ë¦¬ì˜¤ ëª¨ë¸ì—ì„œ ë…ë¦½ë³€ìˆ˜ì—ì„œ ì œì™¸í•  ì»¬ëŸ¼ ì„ íƒ (ì‹¤íŒ¨ìœ¨/ë¶ˆëŸ‰ë¥  ë“±)",
        options=scenario_candidate_cols,
        help="ì‹¤íŒ¨ë¹„ìš©ê³¼ ë„ˆë¬´ ì§ì ‘ì ìœ¼ë¡œ ì—°ê²°ëœ ì§€í‘œë¥¼ ì œì™¸í•˜ë©´ ì‹œë‚˜ë¦¬ì˜¤ ëª¨ë¸ í•´ì„ë ¥ì´ ë†’ì•„ì§‘ë‹ˆë‹¤."
    )

    # (ê¸°ì¡´ ë¡œì§ ê·¸ëŒ€ë¡œ) failure_target_col ê²°ì •: ì„ íƒëœ ì‹¤íŒ¨ë¹„ìš© ì»¬ëŸ¼ë“¤ì„ í™œìš©
    failure_target_col = None
    # 1) ì‹¤íŒ¨ë¹„ìš© ì»¬ëŸ¼ì´ 1ê°œë©´ ê·¸ ì»¬ëŸ¼ì„ ì‚¬ìš©
    if len(failure_selected_cols) == 1 and failure_selected_cols[0] in numeric_cols:
        failure_target_col = failure_selected_cols[0]
    # 2) ì—¬ëŸ¬ ê°œë©´ Noneìœ¼ë¡œ ë‘ê³  build_scenario_result ë‚´ë¶€ í•©ì‚° ì‚¬ìš©
    else:
        failure_target_col = None

    scenario_info, err = build_scenario_result(
        df,
        cost_cols,
        failure_col_name=failure_target_col,
        exclude_cols=scenario_exclude_cols
    )

    if err:
        st.warning(err)
    else:
        base = float(scenario_info["baseline_cost"])
        task_type = scenario_info.get("task_type", "regression")

        def get_min_observed_shares(_df, prevention_cols, appraisal_cols, _failure_target_col):
            df_num = _df.select_dtypes(include=[np.number]).copy()
            p_cols2 = [c for c in prevention_cols if c in df_num.columns]
            a_cols2 = [c for c in appraisal_cols if c in df_num.columns]

            # ì‹¤íŒ¨ë¹„ìš©ì€: ë‹¨ì¼ ì»¬ëŸ¼ì´ë©´ ê·¸ ì»¬ëŸ¼, ì•„ë‹ˆë©´ ì„ íƒëœ ì‹¤íŒ¨ë¹„ìš© ì»¬ëŸ¼ í•©ì‚°
            if _failure_target_col and _failure_target_col in df_num.columns:
                f_cols2 = [_failure_target_col]
            else:
                f_cols2 = [c for c in failure_selected_cols if c in df_num.columns]

            p = df_num[p_cols2].sum(axis=1) if p_cols2 else pd.Series(0.0, index=df_num.index)
            a = df_num[a_cols2].sum(axis=1) if a_cols2 else pd.Series(0.0, index=df_num.index)
            f = df_num[f_cols2].sum(axis=1) if f_cols2 else pd.Series(0.0, index=df_num.index)

            tot = p + a + f
            mask = tot > 0
            if mask.sum() == 0:
                return None

            idx = tot[mask].idxmin()
            tot_min = float(tot.loc[idx])
            return {
                "p_share": float(p.loc[idx]) / tot_min * 100.0,
                "a_share": float(a.loc[idx]) / tot_min * 100.0,
                "f_share": float(f.loc[idx]) / tot_min * 100.0,
            }

        if task_type == "classification":
            colA, colB = st.columns(2)
            with colA:
                prevent_pct = st.slider("ì˜ˆë°©ë¹„ìš© ì¦ê°€ìœ¨ (%)", -50, 200, 0, step=1)
            with colB:
                appraisal_pct = st.slider("í‰ê°€/ê²€ì‚¬ë¹„ìš© ì¦ê°€ìœ¨ (%)", -50, 200, 0, step=1)

            new_cost = scenario_info["predict_func"](prevent_pct / 100.0, appraisal_pct / 100.0)

            base_prob = base
            new_prob = float(new_cost)
            prob_diff = (new_prob - base_prob) * 100  # %p

            c1, c2, c3 = st.columns(3)
            c1.metric("ê¸°ì¤€ ì‹¤íŒ¨ ë°œìƒ í™•ë¥ ", f"{base_prob:.3f}")
            c2.metric("í˜„ì¬ ì‹¤íŒ¨ ë°œìƒ í™•ë¥ ", f"{new_prob:.3f}")
            c3.metric("ë³€í™”", f"{prob_diff:+.2f}%p")

        else:
            # ====== (ê¸°ì¡´ íšŒê·€ ì‹œë‚˜ë¦¬ì˜¤ ë¡œì§ ê·¸ëŒ€ë¡œ) ======
            base_prev = float(scenario_info.get("baseline_prevention", 0.0))
            base_appr = float(scenario_info.get("baseline_appraisal", 0.0))
            base_fail = float(base)

            base_total_q = base_prev + base_appr + base_fail
            if base_total_q <= 0:
                st.warning("ê¸°ì¤€ ì´ í’ˆì§ˆë¹„ìš©(ì˜ˆë°©+í‰ê°€+ì‹¤íŒ¨)ì´ 0 ì´í•˜ë¼ ì‹œë‚˜ë¦¬ì˜¤ ê³„ì‚°ì´ ì–´ë µìŠµë‹ˆë‹¤.")
            else:
                obs = get_min_observed_shares(
                    df,
                    scenario_info.get("prevention_cols", []),
                    scenario_info.get("appraisal_cols", []),
                    failure_target_col
                )
                if obs is None:
                    obs_p = (base_prev / base_total_q * 100.0) if base_total_q > 0 else 10.0
                    obs_a = (base_appr / base_total_q * 100.0) if base_total_q > 0 else 10.0
                else:
                    obs_p, obs_a = obs["p_share"], obs["a_share"]

                def clamp(x, lo, hi):
                    return max(lo, min(hi, x))

                P_FACTOR_MIN, P_FACTOR_MAX = -0.50, 2.00
                A_FACTOR_MIN, A_FACTOR_MAX = -0.50, 2.00

                def predict_from_shares(p_share, a_share):
                    if p_share + a_share >= 100.0:
                        return None

                    p_new_raw = base_total_q * (p_share / 100.0)
                    a_new_raw = base_total_q * (a_share / 100.0)

                    p_factor = (p_new_raw / base_prev - 1.0) if base_prev > 0 else 0.0
                    a_factor = (a_new_raw / base_appr - 1.0) if base_appr > 0 else 0.0
                    p_factor = clamp(p_factor, P_FACTOR_MIN, P_FACTOR_MAX)
                    a_factor = clamp(a_factor, A_FACTOR_MIN, A_FACTOR_MAX)

                    p_new = base_prev * (1.0 + p_factor)
                    a_new = base_appr * (1.0 + a_factor)

                    fail_pred = float(scenario_info["predict_func"](p_factor, a_factor))
                    total_pred = float(p_new + a_new + fail_pred)

                    if total_pred <= 0:
                        return None

                    fail_share_pred = fail_pred / total_pred * 100.0
                    return fail_pred, total_pred, fail_share_pred

                BAND_P = 20.0
                BAND_A = 20.0
                step = 1.0

                p_min = max(0.0, obs_p - BAND_P)
                p_max = min(95.0, obs_p + BAND_P)
                a_min_base = max(0.0, obs_a - BAND_A)
                a_max_base = min(95.0, obs_a + BAND_A)

                LAMBDA = 0.02

                best_score = float("inf")
                best_p_share = None
                best_a_share = None

                p = p_min
                while p <= p_max + 1e-9:
                    a_max = min(a_max_base, 99.0 - p)
                    a = a_min_base
                    while a <= a_max + 1e-9:
                        out = predict_from_shares(p, a)
                        if out is not None:
                            _, total_pred, _ = out
                            reg = LAMBDA * ((p - obs_p) ** 2 + (a - obs_a) ** 2)
                            score = total_pred + reg
                            if score < best_score:
                                best_score = score
                                best_p_share = float(p)
                                best_a_share = float(a)
                        a += step
                    p += step

                if best_p_share is None:
                    st.warning("ìµœì  ë¹„ìœ¨ íƒìƒ‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë°ì´í„°/ì»¬ëŸ¼ ì„ íƒì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
                else:
                    st.markdown(
                        f"ğŸ’¡ **(ì˜ˆì¸¡ ê¸°ë°˜) ì´ í’ˆì§ˆë¹„ìš©ì´ ìµœì†Œê°€ ë˜ëŠ” ë¹„ìœ¨(ì´=100%)**: "
                        f"ì˜ˆë°© **{best_p_share:.0f}%**, í‰ê°€ **{best_a_share:.0f}%**"
                    )

                    
                    if "scenario_p_share" not in st.session_state:
                        st.session_state["scenario_p_share"] = float(best_p_share)
                    if "scenario_a_share" not in st.session_state:
                        st.session_state["scenario_a_share"] = float(best_a_share)

                    colA, colB = st.columns(2)

                    with colA:
                        p_share = st.slider(
                            "ì˜ˆë°©ë¹„ìš© ë¹„ìœ¨",
                            0.0, 95.0,
                            step=1.0,
                            key="scenario_p_share"
                        )

                    remaining = max(1.0, 99.0 - float(p_share))
                    if float(st.session_state.get("scenario_a_share", 0.0)) > remaining:
                        st.session_state["scenario_a_share"] = remaining

                    with colB:
                        a_share = st.slider(
                            "í‰ê°€ë¹„ìš© ë¹„ìœ¨",
                            0.0, remaining,
                            step=1.0,
                            key="scenario_a_share"  
                        )
                        

                    out = predict_from_shares(p_share, a_share)
                    f_share_input = 100.0 - float(p_share) - float(a_share)  # âœ… ì´=100 êµ¬ì„± ì”ì—¬ ì‹¤íŒ¨ë¹„ìœ¨
                    st.caption(f"ì´=100 êµ¬ì„± Â· ì˜ˆë°© {p_share:.0f}% / í‰ê°€ {a_share:.0f}% / ì‹¤íŒ¨ {f_share_input:.0f}%")

                    if out is None:
                        st.warning("í˜„ì¬ ë¹„ìœ¨ ì¡°í•©ì€ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (p+aê°€ 100%ì— ë„ˆë¬´ ê°€ê¹Œì›€/ë¹„í˜„ì‹¤ êµ¬ê°„)")
                    else:
                        new_fail, new_total, new_fail_share = out

                        fail_change_pct = (new_fail / base_fail - 1.0) * 100.0 if base_fail != 0 else 0.0
                        total_change_pct = (new_total / base_total_q - 1.0) * 100.0 if base_total_q != 0 else 0.0

                        base_fail_share = (base_fail / base_total_q) * 100.0 if base_total_q != 0 else 0.0
                        fail_share_delta = float(new_fail_share) - float(base_fail_share)  # í¼ì„¼íŠ¸í¬ì¸íŠ¸ ë³€í™”(pp)

                        #st.metricë¡œ ì§ê´€ í‘œì‹œ
                        def arrow(v: float) -> str:
                            if v > 0:
                                return "ğŸ“ˆ"
                            elif v < 0:
                                return "ğŸ“‰"
                            return "âºï¸"

                        m1, m2, m3= st.columns(3)

                        m1.metric(
                            label=f"{arrow(fail_change_pct)} ì‹¤íŒ¨ë¹„ìš© ë³€í™”",
                            value=f"{fail_change_pct:+.1f}%",
                            delta=float(fail_change_pct),
                            delta_color="inverse"
                        )

                        m2.metric(
                            label=f"{arrow(total_change_pct)} ì „ì²´ í’ˆì§ˆë¹„ìš© ë³€í™”",
                            value=f"{total_change_pct:+.1f}%",
                            delta=float(total_change_pct),
                            delta_color="inverse"
                        )

                        # âœ… ì´=100 êµ¬ì„± ê¸°ì¤€ ì‹¤íŒ¨ë¹„ìœ¨(ì”ì—¬) â€” í•­ìƒ í•©ê³„ 100ì´ ë˜ê²Œ ë³´ì´ëŠ” ê°’
                        m3.metric(
                            label="ğŸ§© ì”ì—¬ ì‹¤íŒ¨ë¹„ìš© ë¹„ìœ¨",
                            value=f"{f_share_input:.1f}%"
                        )

                        st.markdown(
                            """
                            <small style="color: #AAAAAA;">
                            â€» <b>ì•ˆë‚´</b><br>
                            â€˜ì‹¤íŒ¨ë¹„ìš© ë³€í™”(%)â€™ì™€ â€˜ì „ì²´ í’ˆì§ˆë¹„ìš© ë³€í™”(%)â€™ëŠ” ê³¼ê±° ë°ì´í„° í‰ê· ì„ ê¸°ì¤€ìœ¼ë¡œ í•œ ë³€í™”ìœ¨ì…ë‹ˆë‹¤.<br>
                            â€˜ì”ì—¬ ì‹¤íŒ¨ë¹„ìš© ë¹„ìœ¨â€™ì€ ì…ë ¥í•œ ë¹„ìš© êµ¬ì„± ë¹„ìœ¨ì…ë‹ˆë‹¤.<br>
                            ë³¸ â€˜ìµœì  ë¹„ìœ¨â€™ì€ ë¹„í˜„ì‹¤ êµ¬ê°„(p+aê°€ 100%ì— ë§¤ìš° ê·¼ì ‘) ë°
                            ë°ì´í„° ì™¸ì‚½ ìœ„í—˜ êµ¬ê°„ì„ ì œì™¸í•œ ë²”ìœ„ ë‚´ì—ì„œ íƒìƒ‰ëœ ìµœì†Œê°’ì…ë‹ˆë‹¤.
                            </small>
                            """,
                            unsafe_allow_html=True
                        )




# =======================
# 2) ì±—ë´‡ íƒ­
# =======================
with tab_chat:
    st.subheader("Q-COST AIì™€ ëŒ€í™”í•˜ê¸°")
    st.caption("ì˜ˆ: ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ ê²°ê³¼ í•´ì„í•´ì¤˜ / ëª¨ë¸ ì„±ëŠ¥ì„ ìš”ì•½í•´ì¤˜")

    if "messages" not in st.session_state:
        st.session_state["messages"] = []

    for msg in st.session_state["messages"]:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    user_input = st.chat_input("Q-COST, í’ˆì§ˆë¹„ìš©, ë¶„ì„ ê²°ê³¼ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”.")
    if user_input:
        st.session_state["messages"].append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        with st.chat_message("assistant"):
            if not google_api_key:
                st.warning("Google API KEYë¥¼ ì‚¬ì´ë“œë°”ì— ë¨¼ì € ì…ë ¥í•´ ì£¼ì„¸ìš”.")
            else:
                analysis_summary = st.session_state.get("analysis_summary", "")
                try:
                    answer = generate_ai_response(
                        user_input,
                        api_key=google_api_key,
                        analysis_summary=analysis_summary
                    )
                except Exception as e:
                    answer = f"Gemini í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:\n\n{e}"

                st.markdown(answer)
                st.session_state["messages"].append({"role": "assistant", "content": answer})
